#! /usr/bin/env python3

####################################################################################################
#
# Babel - An Electronic Document Management System
# Copyright (C) 2014 Fabrice Salvaire
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
####################################################################################################

""" List the word frequencies of a text document. """

####################################################################################################

import Babel.backend.Logging.Logging as Logging
logger = Logging.setup_logging('babel')

####################################################################################################

import argparse

####################################################################################################

from Babel.backend.Lexique.BritishNationalCorpus import BritishNationalCorpus
from Babel.backend.Pdf.DocumentWords import DocumentWords
from Babel.backend.Pdf.TextTokenizer import TextTokenizer
from Babel.backend.Tools.ProgramOptions import PathAction

####################################################################################################
#
# Options
#

argument_parser = argparse.ArgumentParser(description='Analyse a text file.')

argument_parser.add_argument(
    'path', metavar='FILE.txt',
    action=PathAction,
    help='PDF file',
)

argument_parser.add_argument(
    '--words',
    action='store_true',
    default=False,
    help='Display document words',
)

argument_parser.add_argument(
    '--main-words',
    action='store_true',
    default=False,
    help='Display document main words',
)

args = argument_parser.parse_args()

####################################################################################################

def show_words(text, main_words):

    corpus = BritishNationalCorpus()

    tokenised_text = TextTokenizer().lex(text)
    document_words = DocumentWords()
    for token in tokenised_text.word_iterator():
        document_words.add(str(token).lower())

    print('Words:')
    for word_count in document_words:
        word = corpus[word_count.word]
        if word is not None:
            # print '%6u' % count, word, str([word_row.part_of_speech_tag_id for word_row in word_rows])
            if ((not main_words) or
                (main_words and
                 len(word_count.word) >= 3 and word.is_noun)):
                print('{:6} {}'.format(word_count.count, word_count.word)) # tag
        else:
            print('{:6} {}'.format(word_count.count, word_count.word))

####################################################################################################

with open(args.path) as fh:
    text = fh.read()

if args.words or args.main_words:
    show_words(text, args.main_words)
